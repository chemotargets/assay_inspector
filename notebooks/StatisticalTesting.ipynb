{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical significance: ANOVA followed by Tukey HSD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints_cases_dict = {'half_life': ['Fan_Lombardo_DDPD_eDrug3D_Obach','Fan','Lombardo_DDPD_eDrug3D_Obach'], \n",
    "                        'clearance': ['Lombardo_Astrazeneca_Iwata_Obach_GombarHall_Varma2009_Varma2010','Astrazeneca','Lombardo_Iwata_Obach_GombarHall_Varma2009_Varma2010']}\n",
    "endpoints_sources_dict = {'half_life': [['Obach','Lombardo','eDrug3D','DDPD'], 'Fan'],\n",
    "                          'clearance': [['Lombardo','Iwata','Obach','GombarHall','Varma2009','Varma2010'], 'Astrazeneca']}\n",
    "df_dict = {'half_life': [], 'clearance': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint, cases_list in endpoints_cases_dict.items():\n",
    "    # Load data\n",
    "    all_results = pd.read_csv(f'../results/{endpoint}/{cases_list[0]}/XGBoost_rdkit_ecfp4_metrics_folds.tsv', sep='\\t')\n",
    "    divergent_results = pd.read_csv(f'../results/{endpoint}/{cases_list[1]}/XGBoost_rdkit_ecfp4_metrics_folds.tsv', sep='\\t')\n",
    "    homogenous_results = pd.read_csv(f'../results/{endpoint}/{cases_list[2]}/XGBoost_rdkit_ecfp4_metrics_folds.tsv', sep='\\t')\n",
    "\n",
    "    # Build dataframes\n",
    "    for source in endpoints_sources_dict[endpoint][0]:\n",
    "        df_homogenous = homogenous_results[['seed','fold','r2']].loc[homogenous_results['ref'] == source]\n",
    "        df_homogenous['cv_cycle'] = df_homogenous['seed'].astype(str)+'_'+df_homogenous['fold'].astype(str)\n",
    "        df_homogenous['method'] = 'homogenous'\n",
    "        df_homogenous_all = all_results[['seed','fold','r2']].loc[all_results['ref'] == source]\n",
    "        df_homogenous_all['cv_cycle'] = df_homogenous_all['seed'].astype(str)+'_'+df_homogenous_all['fold'].astype(str)\n",
    "        df_homogenous_all['method'] = 'all'\n",
    "        df_homogenous = pd.concat([df_homogenous, df_homogenous_all], axis=0)\n",
    "        df_homogenous['split'] = 'random'\n",
    "        df_homogenous['source'] = source\n",
    "\n",
    "        df_dict[endpoint].append(df_homogenous)\n",
    "\n",
    "    df_divergent = divergent_results[['seed','fold','r2']].loc[divergent_results['ref'] == endpoints_sources_dict[endpoint][1]]\n",
    "    df_divergent['cv_cycle'] = df_divergent['seed'].astype(str)+'_'+df_divergent['fold'].astype(str)\n",
    "    df_divergent['method'] = 'divergent'\n",
    "    df_divergent_all = all_results[['seed','fold','r2']].loc[all_results['ref'] == endpoints_sources_dict[endpoint][1]]\n",
    "    df_divergent_all['cv_cycle'] = df_divergent_all['seed'].astype(str)+'_'+df_divergent_all['fold'].astype(str)\n",
    "    df_divergent_all['method'] = 'all'\n",
    "    df_divergent = pd.concat([df_divergent, df_divergent_all], axis=0)\n",
    "    df_divergent['split'] = 'random'\n",
    "    df_divergent['source'] = endpoints_sources_dict[endpoint][1]\n",
    "\n",
    "    df_dict[endpoint].append(df_divergent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Examine the parametric testing assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The independence assumption\n",
    "\n",
    "The usage of appropriate sampling mechanisms (such as 5x5 repeated CV) is so important to ensure the samples are sufficiently independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The homogeneity of variances assumption: Levene test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint, df_list in df_dict.items():\n",
    "    print(f'\\n{endpoint}\\n')\n",
    "    \n",
    "    for df in df_list:\n",
    "        print(f'Source: {df[\"source\"].values[0]}')\n",
    "        groups = df.groupby('method')['r2'].apply(list)\n",
    "        stat, pvalue = levene(*groups)\n",
    "        print(f'Levene test for R2: p-value = {pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The normality assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_comparison import make_normality_diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for endpoint, df_list in df_dict.items():\n",
    "    print(f'\\n{endpoint}\\n')\n",
    "    \n",
    "    for df in df_list:\n",
    "        print(f'Source: {df[\"source\"].values[0]}')\n",
    "        make_normality_diagnostic(df.copy(), ['r2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform repeated measures ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_comparison import make_boxplots_parametric, rm_tukey_hsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for endpoint, df_list in df_dict.items():\n",
    "    print(f'\\n{endpoint}\\n')\n",
    "    \n",
    "    for df in df_list:\n",
    "        print(f'Source: {df[\"source\"].values[0]}')\n",
    "        make_boxplots_parametric(df.copy(), ['r2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey HSD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint, df_list in df_dict.items():\n",
    "    print(f'\\n{endpoint}\\n')\n",
    "    \n",
    "    for df in df_list:\n",
    "        print(f'Source: {df[\"source\"].values[0]}')\n",
    "        tukey_results = rm_tukey_hsd(df, \"r2\", \"method\")[0]\n",
    "        print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AssayInspector",
   "language": "python",
   "name": "assayinspector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
